{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies\n",
    "\n",
    "**Note** PySpark has it's own [implementation of pandas api](https://spark.apache.org/docs/3.2.0/api/python/reference/pyspark.pandas/frame.html) which computes the same functionality using distributed computing and clusters under the hood. There are some differences but the methods implemented follow along with the pyspark documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyspark.pandas as pd\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4534327, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4/1/2014 0:11:00</td>\n",
       "      <td>40.7690</td>\n",
       "      <td>-73.9549</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4/1/2014 0:17:00</td>\n",
       "      <td>40.7267</td>\n",
       "      <td>-74.0345</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4/1/2014 0:21:00</td>\n",
       "      <td>40.7316</td>\n",
       "      <td>-73.9873</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/1/2014 0:28:00</td>\n",
       "      <td>40.7588</td>\n",
       "      <td>-73.9776</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4/1/2014 0:33:00</td>\n",
       "      <td>40.7594</td>\n",
       "      <td>-73.9722</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date/Time      Lat      Lon    Base\n",
       "0  4/1/2014 0:11:00  40.7690 -73.9549  B02512\n",
       "1  4/1/2014 0:17:00  40.7267 -74.0345  B02512\n",
       "2  4/1/2014 0:21:00  40.7316 -73.9873  B02512\n",
       "3  4/1/2014 0:28:00  40.7588 -73.9776  B02512\n",
       "4  4/1/2014 0:33:00  40.7594 -73.9722  B02512"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_data = os.path.join('.', \"data\")\n",
    "datas = [pd.read_csv(os.path.join(path_to_data, csv), \n",
    "                     encoding='utf-8') for csv in os.listdir(path_to_data) if 'uber-raw-data' in csv]\n",
    "raw_data = pd.concat( datas, axis = 0 )\n",
    "\n",
    "print( raw_data.shape )\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4534327 entries, 0 to 1028135\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   Date/Time  object \n",
      " 1   Lat        float64\n",
      " 2   Lon        float64\n",
      " 3   Base       object \n",
      "dtypes: float64(2), object(2)\n",
      "memory usage: 173.0+ MB\n"
     ]
    }
   ],
   "source": [
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There are no missing values in the 2014 uber dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date/Time    0\n",
       "Lat          0\n",
       "Lon          0\n",
       "Base         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There are 5 unique Base numbers. Their frequency proportions are shown below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B02617    0.321735\n",
       "B02598    0.307237\n",
       "B02682    0.267468\n",
       "B02764    0.058200\n",
       "B02512    0.045359\n",
       "Name: Base, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.get('Base').value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There are \"hot spots\" where there are several trips to the same/similar location**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lat      Lon     \n",
       "39.6569  -74.2258       1\n",
       "40.7435  -73.9560       1\n",
       "         -73.9568       1\n",
       "         -73.9573       1\n",
       "         -73.9712       1\n",
       "                     ... \n",
       "40.7741  -73.8726    1921\n",
       "40.6449  -73.7822    1947\n",
       "40.6448  -73.7820    2079\n",
       "40.7685  -73.8625    2257\n",
       "40.6448  -73.7819    2299\n",
       "Name: Lon, Length: 574558, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_counts = raw_data.groupby('Lat')['Lon'].value_counts(dropna = True).sort_values()\n",
    "location_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Time-Series Totals**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_time = pd.to_datetime(raw_data.get(\"Date/Time\"), infer_datetime_format = True)\n",
    "date_time.name = 'Ride Count'\n",
    "\n",
    "date_only = date_time.dt.date.value_counts(dropna = True).sort_index()\n",
    "pd.concat([date_only, date_only.rolling(window = 7, min_periods = 1).mean()], \n",
    "                      axis = 1, keys = ['Total Rides', '7-Day Average Rides']).to_csv( os.path.join(path_to_data, 'rides_by_date.csv') )\n",
    "\n",
    "date_time.dt.day_name().value_counts(dropna = True).sort_index().to_csv( os.path.join(path_to_data, 'total_rides_by_day.csv') )\n",
    "\n",
    "location_counts.name = 'Ride Count'\n",
    "location_counts.to_csv( os.path.join(path_to_data, 'total_rides_by_location.csv') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Location Totals**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
